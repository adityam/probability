{"title":"Introduction to Probability","markdown":{"yaml":{"title":"Introduction to Probability"},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nThis is a graduate course on probability and random signals. I am going to assume that everyone is familiar with the basics of undergraduate probability. For example, you should be able to answer the following questions:\n\n- A fair 6-sided dice is rolled twice. What is the probability that the sum of the rolls equals 7?\n- A biased coin with $\\PR({\\rm heads}) = 3/4$ is tossed 10 times. What is the probability of obtaining 3 consecutive heads?\n\nYou should also be familiar with the following concepts:\n\n- Random variables, probability distributions, and expectations\n- Conditional distributions, independet random variables\n\nSome of you might also have seen the following concepts\n\n- Law of large numbers\n- Central limit theorem\n\nIn this course, we revist these topics with a more formal approach. We start with a review of the basic concepts.\n\n## Review of Set Theory\n\n### Basic set operations\n\nA **set** is a collection of objects. We say that a set $B$ is a **subset** of set $A$ (written as $B \\subseteq A$) if all elements of $B$ are also elements of $A$. We say that $B$ is a **proper subset** (written $B \\subsetneq A$) if $B \\subseteq A$ and $B \\neq A$.\n\n:::{#exr-sets}\nLet $A = \\{1, 2, 3\\}$. Find all subsets of $A$.\n:::\n\nThe set of all subsets of $A$ is also called the **power set** of $A$ (denoted by $2^A$). The notation $2^A$ is capturing the fact that the power set of $A$ has $2^{|A|}$ elements. For example, your answer to @exr-sets must have $2^3 = 8$ elements.\n\nGiven two sets $A$ and $B$, we define the **set difference** $A\\setminus B$ to be all elements of $A$ not in $B$. Note that mathematically $A \\setminus B$ is well defined even when $B \\not\\subseteq A$. In particular\n$$\nA \\setminus B = A \\setminus (A \\cap B).\n$$\n\n:::{#exr-set-difference}\nCompute $A \\setminus B$ for the following:\n\n- $A = \\{1,2,3,4\\}$ and $B = \\{1, 2\\}$. \n- $A = \\{1,2,3,4\\}$ and $B = \\{1, 2, 5\\}$. \n:::\n\nGiven a collection $\\{A_1, A_2, \\dots, A_n\\}$ of sets, we define two operations:\n\n- **Union** $A_1 \\cup A_2  \\cup \\cdots \\cup A_n$ as follows\n  $$\n    \\bigcup_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for some } i \\}\n  $$\ni.e., an element belongs to $A_1 \\cup A_2  \\cup \\cdots \\cup A_n$ if it belongs to at least one of $A_1$, $A_2$, $\\ldots$, $A_n$.\n\n- **Intersection** $A_1 \\cap A_2  \\cap \\cdots \\cap A_n$ as follows\n  $$\n    \\bigcap_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for all } i \\}\n  $$\ni.e., an element belongs to $A_1 \\cap A_2  \\cap \\cdots \\cap A_n$ if it belongs to all of $A_1$, $A_2$, $\\ldots$, $A_n$.\n\nA collection $\\{A_1, A_2, \\dots, A_n\\}$ is **disjoint** if for every $i \\neq j$, $A_i \\cap A_j = \\emptyset$, where $\\emptyset$ denotes the empty set.\n\nGiven a **universal set** $Ω$ and a collection $\\{A_1, A_2, \\dots, A_n\\}$ of subsets of $Ω$, we say that $\\{A_1, A_2, \\dots, A_n\\}$ is a **partition** of $Ω$ if $\\{A_1, A_2, \\dots, A_n\\}$ are disjoint and $\\bigcup_{i=1}^n A_i = Ω$. \n\n<!-- FIXME: Add a diagram -->\n\n:::{#exm-partion}\nLet $Ω = \\{1,2,3,4\\}$. The following are partitions of $Ω$:\n\n- $\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\{4\\} \\}$.\n- $\\{ \\{1, 2\\}, \\{3, 4\\} \\}$.\n- $\\{ \\{1\\}, \\{2, 3\\}, \\{4\\} \\}$.\n\nThe follow are **not** partitions of $Ω$ [Explain why?]\n\n- $\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\}$.\n- $\\{ \\{1, 2, 3\\}, \\{3, 4\\} \\}$.\n- $\\{ \\{1\\}, \\{2, 3\\}, \\{4, 5\\} \\}$.\n:::\n\nIn most of our discussion, we will work with a pre-specified universal set $Ω$. In this setting we use $A^c$ (read: $A$-complement) as a short hand for $Ω\\setminus A$. \n\n### Properties of set operations\n\n- **Commutative** \n  $$A \\cup B = B \\cup A\n  \\quad\\text{and}\\quad\n  A \\cap B = B \\cap A$$\n\n- **Associative**\n  $$A \\cup (B \\cup C)= (A \\cup B) \\cup C\n  \\quad\\text{and}\\quad\n  A \\cap (B \\cap C)= (A \\cap B) \\cap C$$\n\n- **Distributive**\n  $$A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cap C)\n  \\quad\\text{and}\\quad\n  A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)$$\n\n- **De Morgan's Law**\n  $$(A \\cup B)^c = A^c \\cap B^\\cap\n  \\quad\\text{and}\\quad\n  (A \\cap B)^c = A^c \\cup B^c$$\n\n:::{#exr-set-properties}\nUse distributive property to simplify:\n\n- $[1,4] \\cap ([0,2] \\cup [3,5])$.\n- $[2,4] \\cup ([3,5] \\cap [1,4])$.\n:::\n\n### An algebra (or field) on sets\n\nGiven a universal set $Ω$, a collection $\\ALPHABET F = \\{F_1, F_2, \\dots, F_m\\}$ of subsets of $Ω$ is called an **algebra** if it satisfies the following properties:\n\n- $\\emptyset \\in \\ALPHABET F$ and $Ω \\in \\ALPHABET F$.\n- **Closed under complements**: if $A \\in \\ALPHABET F$ then $A^c \\in \\ALPHABET F$.\n- **Closed under finite unions and finite intersections**: if $A_1, \\dots, A_n \\in \\ALPHABET F$, then \n  $$\n  A_1 \\cup A_2 \\cup \\cdots \\cup A_n \\in \\ALPHABET F\n  \\quad\\text{and}\\quad\n  A_1 \\cap A_2 \\cap \\cdots \\cap A_n \\in \\ALPHABET F\n  $$\n\nWe will sometimes use the notation \"$(Ω,\\ALPHABET F)$ is an algebra of sets\" or \"$\\ALPHABET F$ is an algebra on $Ω$\". Some examples of algebras are as follows:\n\n- The smallest algebra associated with $Ω$ is $\\{\\emptyset, Ω\\}$. \n- If $A$ is any subset of $Ω$, then $\\{\\emptyset, A, A^c, Ω\\}$ is an algebra. \n- For any set $Ω$, the power-set $2^Ω$ is an algebra on $Ω$.\n  As an illustration, check that the power set defined in @exr-sets is an algebra.\n- For those of you who have formally studied boolean algebra, it is an example of an algebra on sets. \n\n## Probability Space\n\nProbability is a measure of uncertainty or our belief that a particular statement is true. In this course, we will not concerns ourselves with how such a measure of uncertainty is constructed; rather focus on the mathematical properties that it should satisfy and the implications of these properties. \n\nMany everyday statements take the form: \"The chance (or probability) of $A$ is $p$\", where $A$ is some event (such as \"sun shining tomorrow\", \"Team A winning a hockey game\", etc.) and $p$ is a number (e.g., $1/8$) or an adjective describing quantity (e.g., \"low\"). \n\nTo mathematically model such statements, we need to model the sequence of events that may lead to the occurance of $A$: this is called a **random experiment**; the result of an experiment is called an **outcome**.  \n\nIn general, the outcome of an experiment is not certain. We can only talk about the collection of possible outcomes. The collection of possible outcomes of an experiment is called the **sample space** and denoted by $Ω$. \n\n:::{#exm-sample-space-coin-toss}\n  What is the sample space for the toss of a coin?\n:::\n\n:::{#exm-sample-space-die-roll}\n  What is the sample space for the roll of a (6-sided) die?\n:::\n\nAn **event** is any subset of the sample space. Some examples of events are:\n\n- Head occurs in @exm-sample-space-coin-toss\n- Both head and tail occur in @exm-sample-space-coin-toss (this is an event that cannot happen, sometimes called the **impossible event**)\n- An even number is thrown in @exm-sample-space-die-roll.\n\nNote that events are subset of the sample space but not all subsets of a sample space may be events. The reasons are too complicated to explain, but the high-level explanation is that everything is okay for discrete sample spaces, but weird things can happen in continuous sample spaces. \n\n**Probability** (denoted by $\\PR$) is a function which assigns a number between $0$ and $1$ to every event. This number indicates what is the _chance_ that the event occurs. Such a function should satisfy some axioms, which we will explain below. \n\nFirst, to define a function, we need to define it's domain and range. Let's denote the domain (i.e., the set of all events to which we can assign a probability) by $\\ALPHABET F$. We expect probability to satisfy certain properties, which imposes constraints on the domain:\n\n- Probability of an impossible event (e.g., getting both heads and tails when we toss a coin) should be zero. Thus, $\\emptyset \\in \\ALPHABET F$.\n\n- Probability of something happening (e.g., getting either a head or a tail when we toss a coin) should be one. Thus, $Ω \\in \\ALPHABET F$. \n\n- If we assign probability to an event $A$ then we should be able to assign probability to \"$A$ does not occur\" i.e., $A^c$. Thus, if $A \\in \\ALPHABET F$ then $A^c \\in \\ALPHABET F$. \n\n- If we can talk about probability of $A$ and $B$ and $A$ and $B$ are disjoint, then we should be able to talk about probability that either $A$ or $B$ occurs and both $A$ and $B$ occur. Thus, if $A, B \\in \\ALPHABET F$, then $A \\cup B \\in \\ALPHABET F$ and $A \\cap B \\in \\ALPHABET F$. \n\nThus, the domain of $\\PR$ **must be an algebra**! However, when we go beyond finite sample spaces, being an algebra is not sufficient as is illustrated by the following example. \n\n::: {#exm-infinite-coin-tosses}\nA coin is tossed repeatedly until a head turns up. The sample space is $Ω = \\{ω_1, ω_2, \\dots\\}$ where $ω_n$ denotes the event that the first $n-1$ tosses are tails followed by a head. \n:::\n\nSuppose we are interested in finding the probability of the event that the coin is tossed an even number of times, i.e., $A = \\{ω_2, ω_4, \\dots\\}$. Note that $ω_2, ω_4, \\dots \\in \\ALPHABET F$. However, $A$ is a \\emph{countable} set. If we want to assign probability to $A$ in terms of probability of $ω_n$, we require $\\ALPHABET F$ to be closed under **countable unions**. This motivates the following definition.\n\n:::{.callout-tip}\n### $σ$-algebra\n\nGiven a universal set $Ω$, a collection $\\ALPHABET F = \\{F_1, F_2, \\dots\\}$ of subsets of $Ω$ is called a **$\\boldsymbol{σ}$-algebra** if it satisfies the following properties:\n\n- $\\emptyset \\in \\ALPHABET F$ and $Ω \\in \\ALPHABET F$.\n- **Closed under complements**: if $A \\in \\ALPHABET F$ then $A^c \\in \\ALPHABET F$.\n- **Closed under [countable]{.text-danger} unions**: if $A_1, A_2, \\dots \\in \\ALPHABET F$, then \n  $$\n  \\bigcup_{n=1}^∞ A_n \\in \\ALPHABET F\n  $$\n:::\n\n:::{#def-probability}\n### Probability space\n\nA probability space is a tuple $(Ω, \\ALPHABET F, \\PR)$ comprising of a set $Ω$, a $σ$-algebra $\\ALPHABET F$ on $Ω$, and a function $\\PR \\colon \\ALPHABET F \\to [0,1]$ that satisfies the following **axioms of proability**\n\na) $\\PR(\\emptyset) = 0$ and $\\PR(Ω) = 1$.\nb) **Countale additivity.** If $A_1, A_2, \\dots Ω$ is a collection of disjoint events in $\\ALPHABET F$, then,\n$$\n\\PR\\biggl( \\bigcup_{n=1}^∞ A_n \\biggr) =\n\\sum_{n=1}^∞ \\PR(A_n).\n$$\n:::\n\n\nSome immediate implications of the axioms of probability are the following.\n\n:::{#lem-probability-properties}\n### Properties of probability measures\n\na. $\\PR(A^c) = 1 - \\PR(A)$. \nb. **Monotonicity.** If $A \\subset B$, then $\\PR(B) = \\PR(A) + \\PR(B \\setminus A) \\ge \\PR(A)$.\nc. **Continuity.** Let $A_1, A_2, \\dots$ be (weakly) increasing sequence of events, i.e., $A_1 \\subseteq A_2 \\subseteq A_3 \\subseteq \\cdots$. Define\n$$\n  A = \\lim_{n \\to ∞} A_n = \\bigcup_{n=1}^∞ A_n.\n$$\nThen, \n$$\n  \\PR(A) = \\lim_{n \\to ∞} \\PR(A_n).\n$$\n\n    Similarly, let $B_1, B_2, \\dots$ be (weakly) decreasing sequence of events, i.e., $B_1 \\supseteq B_2 \\supseteq B_3 \\supseteq \\cdots$. Define\n    $$\n      B = \\lim_{n \\to ∞} B_n = \\bigcup_{n=1}^∞ B_n.\n    $$\n    Then, \n    $$\n      \\PR(B) = \\lim_{n \\to ∞} \\PR(B_n).\n    $$\n:::\n\n:::{.callout-note collapse=\"true\"}\n### Proof\n\nThe proof of parts (a) and (b) is elementary and left as an exercise. Part (c) is more technical and is essentially equivalent to _countable_ additivity. See the textbook for a proof.\n:::\n\n:::{.callout-tip}\n### Some terminology\n\n- An event $A$ is called **null** if $\\PR(A) = 0$. \n  Null event should not be confused with impossible event $\\emptyset$. \n- We say that $A$ occurs **almost surely** (abbreviated to a.s.) if $\\PR(A) = 1$. \n:::\n\n## Conditional Probability\n\nConditional probabilities quantify the uncertainty of an event when it is known that another event has occured. \n\n:::{#def-conidtional-probability}\nLet $(Ω,\\ALPHABET F, \\PR)$ be a probability space and $A, B \\in \\ALPHABET F$ such that $\\PR(B) > 0$. \nThen, the **conditional probability** that $A$ occurs given that $B$ occurs is defined as\n$$\n\\PR(A | B) = \\dfrac{ \\PR(A \\cap B) }{ \\PR(B) }.\n$$\n:::\n\nThe notation $\\PR(A | B)$ is read as \"probability of $A$ given $B$\" or \"probability of $A$ conditioned on $B$\". \n\n:::{#exm-conidtional-dice}\n\n:::\n\n:::{#exm-conidtional-boys-and-girls}\n\n:::\n\n:::{#lem-total-probability}\n### Law of total probability\n\nLet $\\{B_1, B_2, \\dots, B_m\\}$ be a partition of $Ω$ such that $\\PR(B_i) > 0$ for all $i$. Then,\n$$\n\\PR(A) = \\sum_{i=1}^m \\PR(A | B_i) \\PR(B_i).\n$$\n:::\n\n:::{.callout-note collapse=\"true\"}\n### Proof\nConsider $m=2$, in which case the result can be simplified as\n$$\\PR(A) = \\PR(A|B)\\PR(B) + \\PR(A|B^c) \\PR(B^c).$$\n\nTo prove this observe that \n\\begin{equation}\\label{eq:two-step}\nA = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c).\n\\end{equation}\nThe events $A \\cap B$ and $A \\cap B^c$ are disjoint. Therefore, by additivity, we have\n$$\n\\PR(A) = \\PR(A \\cap B) + \\PR(A \\cap B^c).\n$$\nThen, by the definition of conditional probability, we have \n$\\PR(A \\cap B) = \\PR(A|B) \\PR(B)$ and $\\PR(A \\cap B^c) = \\PR(A|B^c) \\PR(B^c)$. Substituting in the above, we get \\eqref{eq:two-step}.\n\nThe argument for the general case is similar. \n:::\n","srcMarkdownNoYaml":"\n\n## Background\n\nThis is a graduate course on probability and random signals. I am going to assume that everyone is familiar with the basics of undergraduate probability. For example, you should be able to answer the following questions:\n\n- A fair 6-sided dice is rolled twice. What is the probability that the sum of the rolls equals 7?\n- A biased coin with $\\PR({\\rm heads}) = 3/4$ is tossed 10 times. What is the probability of obtaining 3 consecutive heads?\n\nYou should also be familiar with the following concepts:\n\n- Random variables, probability distributions, and expectations\n- Conditional distributions, independet random variables\n\nSome of you might also have seen the following concepts\n\n- Law of large numbers\n- Central limit theorem\n\nIn this course, we revist these topics with a more formal approach. We start with a review of the basic concepts.\n\n## Review of Set Theory\n\n### Basic set operations\n\nA **set** is a collection of objects. We say that a set $B$ is a **subset** of set $A$ (written as $B \\subseteq A$) if all elements of $B$ are also elements of $A$. We say that $B$ is a **proper subset** (written $B \\subsetneq A$) if $B \\subseteq A$ and $B \\neq A$.\n\n:::{#exr-sets}\nLet $A = \\{1, 2, 3\\}$. Find all subsets of $A$.\n:::\n\nThe set of all subsets of $A$ is also called the **power set** of $A$ (denoted by $2^A$). The notation $2^A$ is capturing the fact that the power set of $A$ has $2^{|A|}$ elements. For example, your answer to @exr-sets must have $2^3 = 8$ elements.\n\nGiven two sets $A$ and $B$, we define the **set difference** $A\\setminus B$ to be all elements of $A$ not in $B$. Note that mathematically $A \\setminus B$ is well defined even when $B \\not\\subseteq A$. In particular\n$$\nA \\setminus B = A \\setminus (A \\cap B).\n$$\n\n:::{#exr-set-difference}\nCompute $A \\setminus B$ for the following:\n\n- $A = \\{1,2,3,4\\}$ and $B = \\{1, 2\\}$. \n- $A = \\{1,2,3,4\\}$ and $B = \\{1, 2, 5\\}$. \n:::\n\nGiven a collection $\\{A_1, A_2, \\dots, A_n\\}$ of sets, we define two operations:\n\n- **Union** $A_1 \\cup A_2  \\cup \\cdots \\cup A_n$ as follows\n  $$\n    \\bigcup_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for some } i \\}\n  $$\ni.e., an element belongs to $A_1 \\cup A_2  \\cup \\cdots \\cup A_n$ if it belongs to at least one of $A_1$, $A_2$, $\\ldots$, $A_n$.\n\n- **Intersection** $A_1 \\cap A_2  \\cap \\cdots \\cap A_n$ as follows\n  $$\n    \\bigcap_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for all } i \\}\n  $$\ni.e., an element belongs to $A_1 \\cap A_2  \\cap \\cdots \\cap A_n$ if it belongs to all of $A_1$, $A_2$, $\\ldots$, $A_n$.\n\nA collection $\\{A_1, A_2, \\dots, A_n\\}$ is **disjoint** if for every $i \\neq j$, $A_i \\cap A_j = \\emptyset$, where $\\emptyset$ denotes the empty set.\n\nGiven a **universal set** $Ω$ and a collection $\\{A_1, A_2, \\dots, A_n\\}$ of subsets of $Ω$, we say that $\\{A_1, A_2, \\dots, A_n\\}$ is a **partition** of $Ω$ if $\\{A_1, A_2, \\dots, A_n\\}$ are disjoint and $\\bigcup_{i=1}^n A_i = Ω$. \n\n<!-- FIXME: Add a diagram -->\n\n:::{#exm-partion}\nLet $Ω = \\{1,2,3,4\\}$. The following are partitions of $Ω$:\n\n- $\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\{4\\} \\}$.\n- $\\{ \\{1, 2\\}, \\{3, 4\\} \\}$.\n- $\\{ \\{1\\}, \\{2, 3\\}, \\{4\\} \\}$.\n\nThe follow are **not** partitions of $Ω$ [Explain why?]\n\n- $\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\}$.\n- $\\{ \\{1, 2, 3\\}, \\{3, 4\\} \\}$.\n- $\\{ \\{1\\}, \\{2, 3\\}, \\{4, 5\\} \\}$.\n:::\n\nIn most of our discussion, we will work with a pre-specified universal set $Ω$. In this setting we use $A^c$ (read: $A$-complement) as a short hand for $Ω\\setminus A$. \n\n### Properties of set operations\n\n- **Commutative** \n  $$A \\cup B = B \\cup A\n  \\quad\\text{and}\\quad\n  A \\cap B = B \\cap A$$\n\n- **Associative**\n  $$A \\cup (B \\cup C)= (A \\cup B) \\cup C\n  \\quad\\text{and}\\quad\n  A \\cap (B \\cap C)= (A \\cap B) \\cap C$$\n\n- **Distributive**\n  $$A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cap C)\n  \\quad\\text{and}\\quad\n  A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)$$\n\n- **De Morgan's Law**\n  $$(A \\cup B)^c = A^c \\cap B^\\cap\n  \\quad\\text{and}\\quad\n  (A \\cap B)^c = A^c \\cup B^c$$\n\n:::{#exr-set-properties}\nUse distributive property to simplify:\n\n- $[1,4] \\cap ([0,2] \\cup [3,5])$.\n- $[2,4] \\cup ([3,5] \\cap [1,4])$.\n:::\n\n### An algebra (or field) on sets\n\nGiven a universal set $Ω$, a collection $\\ALPHABET F = \\{F_1, F_2, \\dots, F_m\\}$ of subsets of $Ω$ is called an **algebra** if it satisfies the following properties:\n\n- $\\emptyset \\in \\ALPHABET F$ and $Ω \\in \\ALPHABET F$.\n- **Closed under complements**: if $A \\in \\ALPHABET F$ then $A^c \\in \\ALPHABET F$.\n- **Closed under finite unions and finite intersections**: if $A_1, \\dots, A_n \\in \\ALPHABET F$, then \n  $$\n  A_1 \\cup A_2 \\cup \\cdots \\cup A_n \\in \\ALPHABET F\n  \\quad\\text{and}\\quad\n  A_1 \\cap A_2 \\cap \\cdots \\cap A_n \\in \\ALPHABET F\n  $$\n\nWe will sometimes use the notation \"$(Ω,\\ALPHABET F)$ is an algebra of sets\" or \"$\\ALPHABET F$ is an algebra on $Ω$\". Some examples of algebras are as follows:\n\n- The smallest algebra associated with $Ω$ is $\\{\\emptyset, Ω\\}$. \n- If $A$ is any subset of $Ω$, then $\\{\\emptyset, A, A^c, Ω\\}$ is an algebra. \n- For any set $Ω$, the power-set $2^Ω$ is an algebra on $Ω$.\n  As an illustration, check that the power set defined in @exr-sets is an algebra.\n- For those of you who have formally studied boolean algebra, it is an example of an algebra on sets. \n\n## Probability Space\n\nProbability is a measure of uncertainty or our belief that a particular statement is true. In this course, we will not concerns ourselves with how such a measure of uncertainty is constructed; rather focus on the mathematical properties that it should satisfy and the implications of these properties. \n\nMany everyday statements take the form: \"The chance (or probability) of $A$ is $p$\", where $A$ is some event (such as \"sun shining tomorrow\", \"Team A winning a hockey game\", etc.) and $p$ is a number (e.g., $1/8$) or an adjective describing quantity (e.g., \"low\"). \n\nTo mathematically model such statements, we need to model the sequence of events that may lead to the occurance of $A$: this is called a **random experiment**; the result of an experiment is called an **outcome**.  \n\nIn general, the outcome of an experiment is not certain. We can only talk about the collection of possible outcomes. The collection of possible outcomes of an experiment is called the **sample space** and denoted by $Ω$. \n\n:::{#exm-sample-space-coin-toss}\n  What is the sample space for the toss of a coin?\n:::\n\n:::{#exm-sample-space-die-roll}\n  What is the sample space for the roll of a (6-sided) die?\n:::\n\nAn **event** is any subset of the sample space. Some examples of events are:\n\n- Head occurs in @exm-sample-space-coin-toss\n- Both head and tail occur in @exm-sample-space-coin-toss (this is an event that cannot happen, sometimes called the **impossible event**)\n- An even number is thrown in @exm-sample-space-die-roll.\n\nNote that events are subset of the sample space but not all subsets of a sample space may be events. The reasons are too complicated to explain, but the high-level explanation is that everything is okay for discrete sample spaces, but weird things can happen in continuous sample spaces. \n\n**Probability** (denoted by $\\PR$) is a function which assigns a number between $0$ and $1$ to every event. This number indicates what is the _chance_ that the event occurs. Such a function should satisfy some axioms, which we will explain below. \n\nFirst, to define a function, we need to define it's domain and range. Let's denote the domain (i.e., the set of all events to which we can assign a probability) by $\\ALPHABET F$. We expect probability to satisfy certain properties, which imposes constraints on the domain:\n\n- Probability of an impossible event (e.g., getting both heads and tails when we toss a coin) should be zero. Thus, $\\emptyset \\in \\ALPHABET F$.\n\n- Probability of something happening (e.g., getting either a head or a tail when we toss a coin) should be one. Thus, $Ω \\in \\ALPHABET F$. \n\n- If we assign probability to an event $A$ then we should be able to assign probability to \"$A$ does not occur\" i.e., $A^c$. Thus, if $A \\in \\ALPHABET F$ then $A^c \\in \\ALPHABET F$. \n\n- If we can talk about probability of $A$ and $B$ and $A$ and $B$ are disjoint, then we should be able to talk about probability that either $A$ or $B$ occurs and both $A$ and $B$ occur. Thus, if $A, B \\in \\ALPHABET F$, then $A \\cup B \\in \\ALPHABET F$ and $A \\cap B \\in \\ALPHABET F$. \n\nThus, the domain of $\\PR$ **must be an algebra**! However, when we go beyond finite sample spaces, being an algebra is not sufficient as is illustrated by the following example. \n\n::: {#exm-infinite-coin-tosses}\nA coin is tossed repeatedly until a head turns up. The sample space is $Ω = \\{ω_1, ω_2, \\dots\\}$ where $ω_n$ denotes the event that the first $n-1$ tosses are tails followed by a head. \n:::\n\nSuppose we are interested in finding the probability of the event that the coin is tossed an even number of times, i.e., $A = \\{ω_2, ω_4, \\dots\\}$. Note that $ω_2, ω_4, \\dots \\in \\ALPHABET F$. However, $A$ is a \\emph{countable} set. If we want to assign probability to $A$ in terms of probability of $ω_n$, we require $\\ALPHABET F$ to be closed under **countable unions**. This motivates the following definition.\n\n:::{.callout-tip}\n### $σ$-algebra\n\nGiven a universal set $Ω$, a collection $\\ALPHABET F = \\{F_1, F_2, \\dots\\}$ of subsets of $Ω$ is called a **$\\boldsymbol{σ}$-algebra** if it satisfies the following properties:\n\n- $\\emptyset \\in \\ALPHABET F$ and $Ω \\in \\ALPHABET F$.\n- **Closed under complements**: if $A \\in \\ALPHABET F$ then $A^c \\in \\ALPHABET F$.\n- **Closed under [countable]{.text-danger} unions**: if $A_1, A_2, \\dots \\in \\ALPHABET F$, then \n  $$\n  \\bigcup_{n=1}^∞ A_n \\in \\ALPHABET F\n  $$\n:::\n\n:::{#def-probability}\n### Probability space\n\nA probability space is a tuple $(Ω, \\ALPHABET F, \\PR)$ comprising of a set $Ω$, a $σ$-algebra $\\ALPHABET F$ on $Ω$, and a function $\\PR \\colon \\ALPHABET F \\to [0,1]$ that satisfies the following **axioms of proability**\n\na) $\\PR(\\emptyset) = 0$ and $\\PR(Ω) = 1$.\nb) **Countale additivity.** If $A_1, A_2, \\dots Ω$ is a collection of disjoint events in $\\ALPHABET F$, then,\n$$\n\\PR\\biggl( \\bigcup_{n=1}^∞ A_n \\biggr) =\n\\sum_{n=1}^∞ \\PR(A_n).\n$$\n:::\n\n\nSome immediate implications of the axioms of probability are the following.\n\n:::{#lem-probability-properties}\n### Properties of probability measures\n\na. $\\PR(A^c) = 1 - \\PR(A)$. \nb. **Monotonicity.** If $A \\subset B$, then $\\PR(B) = \\PR(A) + \\PR(B \\setminus A) \\ge \\PR(A)$.\nc. **Continuity.** Let $A_1, A_2, \\dots$ be (weakly) increasing sequence of events, i.e., $A_1 \\subseteq A_2 \\subseteq A_3 \\subseteq \\cdots$. Define\n$$\n  A = \\lim_{n \\to ∞} A_n = \\bigcup_{n=1}^∞ A_n.\n$$\nThen, \n$$\n  \\PR(A) = \\lim_{n \\to ∞} \\PR(A_n).\n$$\n\n    Similarly, let $B_1, B_2, \\dots$ be (weakly) decreasing sequence of events, i.e., $B_1 \\supseteq B_2 \\supseteq B_3 \\supseteq \\cdots$. Define\n    $$\n      B = \\lim_{n \\to ∞} B_n = \\bigcup_{n=1}^∞ B_n.\n    $$\n    Then, \n    $$\n      \\PR(B) = \\lim_{n \\to ∞} \\PR(B_n).\n    $$\n:::\n\n:::{.callout-note collapse=\"true\"}\n### Proof\n\nThe proof of parts (a) and (b) is elementary and left as an exercise. Part (c) is more technical and is essentially equivalent to _countable_ additivity. See the textbook for a proof.\n:::\n\n:::{.callout-tip}\n### Some terminology\n\n- An event $A$ is called **null** if $\\PR(A) = 0$. \n  Null event should not be confused with impossible event $\\emptyset$. \n- We say that $A$ occurs **almost surely** (abbreviated to a.s.) if $\\PR(A) = 1$. \n:::\n\n## Conditional Probability\n\nConditional probabilities quantify the uncertainty of an event when it is known that another event has occured. \n\n:::{#def-conidtional-probability}\nLet $(Ω,\\ALPHABET F, \\PR)$ be a probability space and $A, B \\in \\ALPHABET F$ such that $\\PR(B) > 0$. \nThen, the **conditional probability** that $A$ occurs given that $B$ occurs is defined as\n$$\n\\PR(A | B) = \\dfrac{ \\PR(A \\cap B) }{ \\PR(B) }.\n$$\n:::\n\nThe notation $\\PR(A | B)$ is read as \"probability of $A$ given $B$\" or \"probability of $A$ conditioned on $B$\". \n\n:::{#exm-conidtional-dice}\n\n:::\n\n:::{#exm-conidtional-boys-and-girls}\n\n:::\n\n:::{#lem-total-probability}\n### Law of total probability\n\nLet $\\{B_1, B_2, \\dots, B_m\\}$ be a partition of $Ω$ such that $\\PR(B_i) > 0$ for all $i$. Then,\n$$\n\\PR(A) = \\sum_{i=1}^m \\PR(A | B_i) \\PR(B_i).\n$$\n:::\n\n:::{.callout-note collapse=\"true\"}\n### Proof\nConsider $m=2$, in which case the result can be simplified as\n$$\\PR(A) = \\PR(A|B)\\PR(B) + \\PR(A|B^c) \\PR(B^c).$$\n\nTo prove this observe that \n\\begin{equation}\\label{eq:two-step}\nA = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c).\n\\end{equation}\nThe events $A \\cap B$ and $A \\cap B^c$ are disjoint. Therefore, by additivity, we have\n$$\n\\PR(A) = \\PR(A \\cap B) + \\PR(A \\cap B^c).\n$$\nThen, by the definition of conditional probability, we have \n$\\PR(A \\cap B) = \\PR(A|B) \\PR(B)$ and $\\PR(A \\cap B^c) = \\PR(A|B^c) \\PR(B^c)$. Substituting in the above, we get \\eqref{eq:two-step}.\n\nThe argument for the general case is similar. \n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":"inline"},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","include-in-header":["static/html/mathjax.html","static/html/clicky.html"],"reference-location":"margin","filters":["_extensions/schochastics/nutshell/nutshell.lua"],"embed-resources":false,"toc":true,"number-sections":true,"output-file":"probability-spaces.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.554","author":[{"name":"Aditya Mahajan","url":"https://adityam.github.io","affiliation":"McGill University","affiliation-url":"http://www.mcgill.ca/ece"}],"theme":{"light":["lumen","static/css/style.scss"],"dark":["darkly","static/css/style.scss"]},"mermaid":{"theme":"neutral"},"published-title":"Updated","date":"last-modified","smooth-scroll":true,"jupyter":"julia-1.9","title":"Introduction to Probability"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}