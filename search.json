[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Outline",
    "section": "",
    "text": "Instructor\n\n\nAditya Mahajan\nOffice Hours: TBD\n\n\nTeaching Assistants\n\n\nTBD\n\n\nLectures\n\n\n2:35pm–3:55pm Monday, Wednesday (ENGTR 2100)\n\n\nTutorials\n\n\n12:35am–1:25am Friday, (ENGTR 2100)\n\n\nPrerequisites\n\n\nECSE 205 (Probability and Random Signals I)\nECSE 206 or ECSE 316 (Signals and Systems)\n\n\nCommunication\n\nUse the discussion board on myCourses for all questions related to the course. Only personal emails related to medical exceptions for missing a deliverable will be answered.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nMaterial Covered\n\n\n\n\n1\nProbability spaces, algebra of events, axioms of probability\n\n\n2\nRandom variables and random vectors\n\n\n3\nDiscrete and continuous random variables\n\n\n4\nConditional distributions and conditional expectations\n\n\n5\nMoment generating functions and sums of random variables\n\n\n6\nProbability inequalities\n\n\n7\nReview and Mid-Term\n\n\n8\nConvergence in probability and the weak law of large numbers\n\n\n9\nAlmost sure convergence and the strong law of large numbers\n\n\n10\nMaximum likelihood estimation and minimum mean squared error estimation\n\n\n11\nStochastic processes, Bernoulli process, Poisson process, and Gaussian process\n\n\n12\nMarkov chains\n\n\n13\nWide sense stationary processes\n\n\n\n\n\n\n\nTextbook\n\n\nGrimmett and Stirzaker, “Probability and Random Processes”, 4th edition, Oxford University Press\n\n\n\n\n\n\n\nAssignments (20%) Weekly homework assignments. Typically, each assignment will consist of four questions, out of which one or two randomly selected questions will be grader. The lowest two homework assignments will be dropped.\nMid Term (25%) Closed book in-class exam. Oct 9 (during class time)\nFinal Exam (50%) Closed book, in-person exam. Will be scheduled by the exam office and the dates will be announced later.\nThe final exam will cover all the material seen in the class during the term.\n\n\n\n\n\nAssignments must be submitted electronically on myCourses as a PDF. You may write the assignments on paper and then scan them as a PDF (there are several such apps available for all phone platforms), or write on a tablet and convert to PDF, or type using a word processor.\nThere will no make-up examination for students who miss a mid-term.\n\nStudent who miss the exam due to a valid reason (see Faculty of Engineering policy) should notify the instructor within a week of the exam and provide necessary documentation.\nIf, and only if, proper documentation for a missed exam is presented, the marks for the missed exam will be shifted to the final exam.\nStudents who miss the mid-term exam for any other reason (e.g., no medical note, going to the exam at the wrong time, or on the wrong day, etc.) will get zero marks on the exam.\n\nAny request for reevaluation of a mid-term or an assignment must be made in writing within a week of its return. Note that requesting a re-grade will mean that you WHOLE assignment or exam will be re-graded.\nDue to paucity of grading hours, only one or two randomly selected questions will be graded in each assignment.\nThe lowest two assignments and labs will be dropped. There will be no make-up for missed assignments and labs, even if it is for a valid reason. The whole point of dropping the lowest two assignments/labs is to reduce the administrative overhead of keeping track of such missed assignments/labs.\n\n\nRight to submit in English or French written work that is to be graded.\n\nIn accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded.\n\nAcademic Integrity\n\nMcGill University values academic integrity. Therefore all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see McGill’s guide to academic honesty for more information).\nL’université McGill attache une haute importance à l’honnêteté académique. Il incombe par conséquent à tous les étudiants de comprendre ce que l’on entend par tricherie, plagiat et autres infractions académiques, ainsi que les conséquences que peuvent avoir de telles actions, selon le Code de conduite de l’étudiant et des procédures disciplinaires (pour de plus amples renseignements, veuillez consulter le guide pour l’honnêteté académique de McGill.)\n\n\n\n\n\nThe course is taught in a “chalk and board” style; there will be no power point presentations. All students are expected to attend lectures and take notes. Partial notes on some of the material will be provided, but are not a substitute for the material covered in class.\n© Instructor-generated course materials (e.g., handouts, notes, summaries, exam questions) are protected by law and may not be copied or distributed in any form or in any medium without explicit permission of the instructor. Note that infringements of copyright can be subject to follow up by the University under the Code of Student Conduct and Disciplinary Procedures.\n\n\n\n\nAs the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or contact the office of Student Accessibility and Achievement.\nEnd-of-course evaluations are one of the ways that McGill works towards maintaining and improving the quality of courses and the student’s learning experience. You will be notified by e-mail when the evaluations are available. Please note that a minimum number of responses must be received for results to be available to students."
  },
  {
    "objectID": "index.html#general-information",
    "href": "index.html#general-information",
    "title": "Course Outline",
    "section": "",
    "text": "Instructor\n\n\nAditya Mahajan\nOffice Hours: TBD\n\n\nTeaching Assistants\n\n\nTBD\n\n\nLectures\n\n\n2:35pm–3:55pm Monday, Wednesday (ENGTR 2100)\n\n\nTutorials\n\n\n12:35am–1:25am Friday, (ENGTR 2100)\n\n\nPrerequisites\n\n\nECSE 205 (Probability and Random Signals I)\nECSE 206 or ECSE 316 (Signals and Systems)\n\n\nCommunication\n\nUse the discussion board on myCourses for all questions related to the course. Only personal emails related to medical exceptions for missing a deliverable will be answered."
  },
  {
    "objectID": "index.html#course-content",
    "href": "index.html#course-content",
    "title": "Course Outline",
    "section": "",
    "text": "Week\nMaterial Covered\n\n\n\n\n1\nProbability spaces, algebra of events, axioms of probability\n\n\n2\nRandom variables and random vectors\n\n\n3\nDiscrete and continuous random variables\n\n\n4\nConditional distributions and conditional expectations\n\n\n5\nMoment generating functions and sums of random variables\n\n\n6\nProbability inequalities\n\n\n7\nReview and Mid-Term\n\n\n8\nConvergence in probability and the weak law of large numbers\n\n\n9\nAlmost sure convergence and the strong law of large numbers\n\n\n10\nMaximum likelihood estimation and minimum mean squared error estimation\n\n\n11\nStochastic processes, Bernoulli process, Poisson process, and Gaussian process\n\n\n12\nMarkov chains\n\n\n13\nWide sense stationary processes"
  },
  {
    "objectID": "index.html#course-material",
    "href": "index.html#course-material",
    "title": "Course Outline",
    "section": "",
    "text": "Textbook\n\n\nGrimmett and Stirzaker, “Probability and Random Processes”, 4th edition, Oxford University Press"
  },
  {
    "objectID": "index.html#evaluation",
    "href": "index.html#evaluation",
    "title": "Course Outline",
    "section": "",
    "text": "Assignments (20%) Weekly homework assignments. Typically, each assignment will consist of four questions, out of which one or two randomly selected questions will be grader. The lowest two homework assignments will be dropped.\nMid Term (25%) Closed book in-class exam. Oct 9 (during class time)\nFinal Exam (50%) Closed book, in-person exam. Will be scheduled by the exam office and the dates will be announced later.\nThe final exam will cover all the material seen in the class during the term."
  },
  {
    "objectID": "index.html#marking-policy",
    "href": "index.html#marking-policy",
    "title": "Course Outline",
    "section": "",
    "text": "Assignments must be submitted electronically on myCourses as a PDF. You may write the assignments on paper and then scan them as a PDF (there are several such apps available for all phone platforms), or write on a tablet and convert to PDF, or type using a word processor.\nThere will no make-up examination for students who miss a mid-term.\n\nStudent who miss the exam due to a valid reason (see Faculty of Engineering policy) should notify the instructor within a week of the exam and provide necessary documentation.\nIf, and only if, proper documentation for a missed exam is presented, the marks for the missed exam will be shifted to the final exam.\nStudents who miss the mid-term exam for any other reason (e.g., no medical note, going to the exam at the wrong time, or on the wrong day, etc.) will get zero marks on the exam.\n\nAny request for reevaluation of a mid-term or an assignment must be made in writing within a week of its return. Note that requesting a re-grade will mean that you WHOLE assignment or exam will be re-graded.\nDue to paucity of grading hours, only one or two randomly selected questions will be graded in each assignment.\nThe lowest two assignments and labs will be dropped. There will be no make-up for missed assignments and labs, even if it is for a valid reason. The whole point of dropping the lowest two assignments/labs is to reduce the administrative overhead of keeping track of such missed assignments/labs.\n\n\nRight to submit in English or French written work that is to be graded.\n\nIn accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded.\n\nAcademic Integrity\n\nMcGill University values academic integrity. Therefore all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see McGill’s guide to academic honesty for more information).\nL’université McGill attache une haute importance à l’honnêteté académique. Il incombe par conséquent à tous les étudiants de comprendre ce que l’on entend par tricherie, plagiat et autres infractions académiques, ainsi que les conséquences que peuvent avoir de telles actions, selon le Code de conduite de l’étudiant et des procédures disciplinaires (pour de plus amples renseignements, veuillez consulter le guide pour l’honnêteté académique de McGill.)"
  },
  {
    "objectID": "index.html#course-delivery",
    "href": "index.html#course-delivery",
    "title": "Course Outline",
    "section": "",
    "text": "The course is taught in a “chalk and board” style; there will be no power point presentations. All students are expected to attend lectures and take notes. Partial notes on some of the material will be provided, but are not a substitute for the material covered in class.\n© Instructor-generated course materials (e.g., handouts, notes, summaries, exam questions) are protected by law and may not be copied or distributed in any form or in any medium without explicit permission of the instructor. Note that infringements of copyright can be subject to follow up by the University under the Code of Student Conduct and Disciplinary Procedures."
  },
  {
    "objectID": "index.html#additional-notes",
    "href": "index.html#additional-notes",
    "title": "Course Outline",
    "section": "",
    "text": "As the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or contact the office of Student Accessibility and Achievement.\nEnd-of-course evaluations are one of the ways that McGill works towards maintaining and improving the quality of courses and the student’s learning experience. You will be notified by e-mail when the evaluations are available. Please note that a minimum number of responses must be received for results to be available to students."
  },
  {
    "objectID": "probability-spaces.html",
    "href": "probability-spaces.html",
    "title": "Introduction to Probability",
    "section": "",
    "text": "This is a graduate course on probability and random signals. I am going to assume that everyone is familiar with the basics of undergraduate probability. For example, you should be able to answer the following questions:\n\nA fair 6-sided dice is rolled twice. What is the probability that the sum of the rolls equals 7?\nA biased coin with \\(\\PR({\\rm heads}) = 3/4\\) is tossed 10 times. What is the probability of obtaining 3 consecutive heads?\n\nYou should also be familiar with the following concepts:\n\nRandom variables, probability distributions, and expectations\nConditional distributions, independent random variables\n\nSome of you might also have seen the following concepts\n\nLaw of large numbers\nCentral limit theorem\n\nIn this course, we revisit these topics with a more formal approach. We start with a review of the basic concepts."
  },
  {
    "objectID": "probability-spaces.html#background",
    "href": "probability-spaces.html#background",
    "title": "Introduction to Probability",
    "section": "",
    "text": "This is a graduate course on probability and random signals. I am going to assume that everyone is familiar with the basics of undergraduate probability. For example, you should be able to answer the following questions:\n\nA fair 6-sided dice is rolled twice. What is the probability that the sum of the rolls equals 7?\nA biased coin with \\(\\PR({\\rm heads}) = 3/4\\) is tossed 10 times. What is the probability of obtaining 3 consecutive heads?\n\nYou should also be familiar with the following concepts:\n\nRandom variables, probability distributions, and expectations\nConditional distributions, independent random variables\n\nSome of you might also have seen the following concepts\n\nLaw of large numbers\nCentral limit theorem\n\nIn this course, we revisit these topics with a more formal approach. We start with a review of the basic concepts."
  },
  {
    "objectID": "probability-spaces.html#review-of-set-theory",
    "href": "probability-spaces.html#review-of-set-theory",
    "title": "Introduction to Probability",
    "section": "2 Review of Set Theory",
    "text": "2 Review of Set Theory\n\n2.1 Basic set operations\nA set is a collection of objects. We say that a set \\(B\\) is a subset of set \\(A\\) (written as \\(B \\subseteq A\\)) if all elements of \\(B\\) are also elements of \\(A\\). We say that \\(B\\) is a proper subset (written \\(B \\subsetneq A\\)) if \\(B \\subseteq A\\) and \\(B \\neq A\\).\n\nExercise 1 Let \\(A = \\{1, 2, 3\\}\\). Find all subsets of \\(A\\).\n\nThe set of all subsets of \\(A\\) is also called the power set of \\(A\\) (denoted by \\(2^A\\)). The notation \\(2^A\\) is capturing the fact that the power set of \\(A\\) has \\(2^{|A|}\\) elements. For example, your answer to Exercise 1 must have \\(2^3 = 8\\) elements.\nGiven two sets \\(A\\) and \\(B\\), we define the set difference \\(A\\setminus B\\) to be all elements of \\(A\\) not in \\(B\\). Note that mathematically \\(A \\setminus B\\) is well defined even when \\(B \\not\\subseteq A\\). In particular \\[\nA \\setminus B = A \\setminus (A \\cap B).\n\\]\n\nExercise 2 Compute \\(A \\setminus B\\) for the following:\n\n\\(A = \\{1,2,3,4\\}\\) and \\(B = \\{1, 2\\}\\).\n\\(A = \\{1,2,3,4\\}\\) and \\(B = \\{1, 2, 5\\}\\).\n\n\nGiven a collection \\(\\{A_1, A_2, \\dots, A_n\\}\\) of sets, we define two operations:\n\nUnion \\(A_1 \\cup A_2  \\cup \\cdots \\cup A_n\\) as follows \\[\n  \\bigcup_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for some } i \\}\n\\] i.e., an element belongs to \\(A_1 \\cup A_2  \\cup \\cdots \\cup A_n\\) if it belongs to at least one of \\(A_1\\), \\(A_2\\), \\(\\ldots\\), \\(A_n\\).\nIntersection \\(A_1 \\cap A_2  \\cap \\cdots \\cap A_n\\) as follows \\[\n  \\bigcap_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for all } i \\}\n\\] i.e., an element belongs to \\(A_1 \\cap A_2  \\cap \\cdots \\cap A_n\\) if it belongs to all of \\(A_1\\), \\(A_2\\), \\(\\ldots\\), \\(A_n\\).\n\nA collection \\(\\{A_1, A_2, \\dots, A_n\\}\\) is disjoint if for every \\(i \\neq j\\), \\(A_i \\cap A_j = \\emptyset\\), where \\(\\emptyset\\) denotes the empty set.\nGiven a universal set \\(Ω\\) and a collection \\(\\{A_1, A_2, \\dots, A_n\\}\\) of subsets of \\(Ω\\), we say that \\(\\{A_1, A_2, \\dots, A_n\\}\\) is a partition of \\(Ω\\) if \\(\\{A_1, A_2, \\dots, A_n\\}\\) are disjoint and \\(\\bigcup_{i=1}^n A_i = Ω\\).\n\n\nExample 1 Let \\(Ω = \\{1,2,3,4\\}\\). The following are partitions of \\(Ω\\):\n\n\\(\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\{4\\} \\}\\).\n\\(\\{ \\{1, 2\\}, \\{3, 4\\} \\}\\).\n\\(\\{ \\{1\\}, \\{2, 3\\}, \\{4\\} \\}\\).\n\nThe follow are not partitions of \\(Ω\\) [Explain why?]\n\n\\(\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\}\\).\n\\(\\{ \\{1, 2, 3\\}, \\{3, 4\\} \\}\\).\n\\(\\{ \\{1\\}, \\{2, 3\\}, \\{4, 5\\} \\}\\).\n\n\nIn most of our discussion, we will work with a pre-specified universal set \\(Ω\\). In this setting we use \\(A^c\\) (read: \\(A\\)-complement) as a short hand for \\(Ω\\setminus A\\).\n\n\n2.2 Properties of set operations\n\nCommutative \\[A \\cup B = B \\cup A\n\\quad\\text{and}\\quad\nA \\cap B = B \\cap A\\]\nAssociative \\[A \\cup (B \\cup C)= (A \\cup B) \\cup C\n\\quad\\text{and}\\quad\nA \\cap (B \\cap C)= (A \\cap B) \\cap C\\]\nDistributive \\[A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cap C)\n\\quad\\text{and}\\quad\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\]\nDe Morgan’s Law \\[(A \\cup B)^c = A^c \\cap B^\\cap\n\\quad\\text{and}\\quad\n(A \\cap B)^c = A^c \\cup B^c\\]\n\n\nExercise 3 Use distributive property to simplify:\n\n\\([1,4] \\cap ([0,2] \\cup [3,5])\\).\n\\([2,4] \\cup ([3,5] \\cap [1,4])\\).\n\n\n\n\n2.3 An algebra (or field) on sets\nGiven a universal set \\(Ω\\), a collection \\(\\ALPHABET F = \\{F_1, F_2, \\dots, F_m\\}\\) of subsets of \\(Ω\\) is called an algebra if it satisfies the following properties:\n\n\\(\\emptyset \\in \\ALPHABET F\\) and \\(Ω \\in \\ALPHABET F\\).\nClosed under complements: if \\(A \\in \\ALPHABET F\\) then \\(A^c \\in \\ALPHABET F\\).\nClosed under finite unions and finite intersections: if \\(A_1, \\dots, A_n \\in \\ALPHABET F\\), then \\[\nA_1 \\cup A_2 \\cup \\cdots \\cup A_n \\in \\ALPHABET F\n\\quad\\text{and}\\quad\nA_1 \\cap A_2 \\cap \\cdots \\cap A_n \\in \\ALPHABET F\n\\]\n\nWe will sometimes use the notation “\\((Ω,\\ALPHABET F)\\) is an algebra of sets” or “\\(\\ALPHABET F\\) is an algebra on \\(Ω\\)”. Some examples of algebras are as follows:\n\nThe smallest algebra associated with \\(Ω\\) is \\(\\{\\emptyset, Ω\\}\\).\nIf \\(A\\) is any subset of \\(Ω\\), then \\(\\{\\emptyset, A, A^c, Ω\\}\\) is an algebra.\nFor any set \\(Ω\\), the power-set \\(2^Ω\\) is an algebra on \\(Ω\\). As an illustration, check that the power set defined in Exercise 1 is an algebra.\nFor those of you who have formally studied boolean algebra, it is an example of an algebra on sets."
  },
  {
    "objectID": "probability-spaces.html#probability-space",
    "href": "probability-spaces.html#probability-space",
    "title": "Introduction to Probability",
    "section": "3 Probability Space",
    "text": "3 Probability Space\nProbability is a measure of uncertainty or our belief that a particular statement is true. In this course, we will not concerns ourselves with how such a measure of uncertainty is constructed; rather focus on the mathematical properties that it should satisfy and the implications of these properties.\nMany everyday statements take the form: “The chance (or probability) of \\(A\\) is \\(p\\)”, where \\(A\\) is some event (such as “sun shining tomorrow”, “Team A winning a hockey game”, etc.) and \\(p\\) is a number (e.g., \\(1/8\\)) or an adjective describing quantity (e.g., “low”).\nTo mathematically model such statements, we need to model the sequence of events that may lead to the occurrence of \\(A\\): this is called a random experiment; the result of an experiment is called an outcome.\nIn general, the outcome of an experiment is not certain. We can only talk about the collection of possible outcomes. The collection of possible outcomes of an experiment is called the sample space and denoted by \\(Ω\\).\n\nExercise 4 What is the sample space for the toss of a coin?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(Ω = \\{ H, T \\}\\).\n\n\n\n\nExercise 5 What is the sample space for the roll of a (6-sided) die?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(Ω = \\{ 1,2,3,4,5,6 \\}\\).\n\n\n\nAn event is any subset of the sample space. Some examples of events are:\n\nHead occurs in Exercise 4 (\\(A = \\{H\\}\\))\nBoth head and tail occur in Exercise 4 (\\(A = \\emptyset\\); this is an event that cannot happen, sometimes called the impossible event)\nAn even number is thrown in Exercise 5 (\\(A = \\{2,4,6\\}\\)).\n\nNote that events are subset of the sample space but not all subsets of a sample space may be events. The reasons are too complicated to explain, but the high-level explanation is that everything is okay for discrete sample spaces, but weird things can happen in continuous sample spaces.\nProbability (denoted by \\(\\PR\\)) is a function which assigns a number between \\(0\\) and \\(1\\) to every event. This number indicates what is the chance that the event occurs. Such a function should satisfy some axioms, which we will explain below.\nFirst, to define a function, we need to define it’s domain and range. Let’s denote the domain (i.e., the set of all events to which we can assign a probability) by \\(\\ALPHABET F\\). We expect probability to satisfy certain properties, which imposes constraints on the domain:\n\nProbability of an impossible event (e.g., getting both heads and tails when we toss a coin) should be zero. Thus, \\(\\emptyset \\in \\ALPHABET F\\).\nProbability of something happening (e.g., getting either a head or a tail when we toss a coin) should be one. Thus, \\(Ω \\in \\ALPHABET F\\).\nIf we assign probability to an event \\(A\\) then we should be able to assign probability to “\\(A\\) does not occur” i.e., \\(A^c\\). Thus, if \\(A \\in \\ALPHABET F\\) then \\(A^c \\in \\ALPHABET F\\).\nIf we can talk about probability of \\(A\\) and \\(B\\), then we should be able to talk about probability that either \\(A\\) or \\(B\\) occurs and both \\(A\\) and \\(B\\) occur. Thus, if \\(A, B \\in \\ALPHABET F\\), then \\(A \\cup B \\in \\ALPHABET F\\) and \\(A \\cap B \\in \\ALPHABET F\\).\n\nThus, the domain of \\(\\PR\\) must be an algebra! However, when we go beyond finite sample spaces, being an algebra is not sufficient as is illustrated by the following example.\n\nExample 2 A coin is tossed repeatedly until a head turns up. The sample space is \\(Ω = \\{ω_1, ω_2, \\dots\\}\\) where \\(ω_n\\) denotes the event that the first \\(n-1\\) tosses are tails followed by a head.\n\nSuppose we are interested in finding the probability of the event that the coin is tossed an even number of times, i.e., \\(A = \\{ω_2, ω_4, \\dots\\}\\). Note that \\(ω_2, ω_4, \\dots \\in \\ALPHABET F\\). However, \\(A\\) is a set. If we want to assign probability to \\(A\\) in terms of probability of \\(ω_n\\), we require \\(\\ALPHABET F\\) to be closed under countable unions. This motivates the following definition.\n\n\n\n\n\n\n\\(σ\\)-algebra\n\n\n\nGiven a universal set \\(Ω\\), a collection \\(\\ALPHABET F = \\{F_1, F_2, \\dots\\}\\) of subsets of \\(Ω\\) is called a \\(\\boldsymbol{σ}\\)-algebra if it satisfies the following properties:\n\n\\(\\emptyset \\in \\ALPHABET F\\) and \\(Ω \\in \\ALPHABET F\\).\nClosed under complements: if \\(A \\in \\ALPHABET F\\) then \\(A^c \\in \\ALPHABET F\\).\nClosed under countable unions: if \\(A_1, A_2, \\dots \\in \\ALPHABET F\\), then \\[\n\\bigcup_{n=1}^∞ A_n \\in \\ALPHABET F\n\\]\n\n\n\n\n\n\n\n\n\nThe distinction between algebras and \\(σ\\)-algebras is technical. Given collection \\(\\ALPHABET S\\) of subsets of \\(Ω\\), we have the following:\n\nThe power-set \\(2^Ω\\) contains \\(\\ALPHABET S\\). Therefore, there is at least one \\(σ\\)-algebra containing \\(\\ALPHABET S\\).\nIf \\(\\ALPHABET F_1\\) and \\(\\ALPHABET F_2\\) are \\(σ\\)-algebras containing \\(\\ALPHABET S\\), then \\(\\ALPHABET F_1 \\cap \\ALPHABET F_2\\) also contains \\(\\ALPHABET S\\).\n\nThus, if we take the intersection of all \\(σ\\)-algebras containing \\(\\ALPHABET S\\), we get the smallest \\(σ\\)-algebra containing \\(\\ALPHABET S\\), which is sometimes denoted by \\(σ(\\ALPHABET S)\\).\nOne commonly used \\(σ\\)-algebra is the Borel \\(σ\\)-algebra, which is defined as follows.1 Let \\(Ω\\) be a subset of \\(\\reals\\) and \\(\\ALPHABET S\\) be the collection of all open intervals in \\(Ω\\). Then \\(σ(\\ALPHABET S)\\) is called the “Borel \\(σ\\)-algebra on Ω” and often denoted by \\(\\mathscr{B}(Ω)\\).\n\n\n\n1 Borel \\(σ\\)-algebra is usually defined for any topological space. We restrict our definition to subsets of reals.\nDefinition 1 (Probability space) A probability space is a tuple \\((Ω, \\ALPHABET F, \\PR)\\) comprising of a set \\(Ω\\), a \\(σ\\)-algebra \\(\\ALPHABET F\\) on \\(Ω\\), and a function \\(\\PR \\colon \\ALPHABET F \\to [0,1]\\) that satisfies the following axioms of proability\n\n\\(\\PR(\\emptyset) = 0\\) and \\(\\PR(Ω) = 1\\).\nCountable additivity. If \\(A_1, A_2, \\dots Ω\\) is a collection of disjoint events in \\(\\ALPHABET F\\), then, \\[\n\\PR\\biggl( \\bigcup_{n=1}^∞ A_n \\biggr) =\n\\sum_{n=1}^∞ \\PR(A_n).\n\\]\n\n\nSome immediate implications of the axioms of probability are the following.\n\nLemma 1 (Properties of probability measures)  \n\n\\(\\PR(A^c) = 1 - \\PR(A)\\).\nMonotonicity. If \\(A \\subset B\\), then \\(\\PR(B) = \\PR(A) + \\PR(B \\setminus A) \\ge \\PR(A)\\).\nContinuity. Let \\(A_1, A_2, \\dots\\) be (weakly) increasing sequence of events, i.e., \\(A_1 \\subseteq A_2 \\subseteq A_3 \\subseteq \\cdots\\). Define \\[\n  A = \\lim_{n \\to ∞} A_n = \\bigcup_{n=1}^∞ A_n.\n\\] Then, \\[\n  \\PR(A) = \\lim_{n \\to ∞} \\PR(A_n).\n\\]\nSimilarly, let \\(B_1, B_2, \\dots\\) be (weakly) decreasing sequence of events, i.e., \\(B_1 \\supseteq B_2 \\supseteq B_3 \\supseteq \\cdots\\). Define \\[\n   B = \\lim_{n \\to ∞} B_n = \\bigcup_{n=1}^∞ B_n.\n\\] Then, \\[\n   \\PR(B) = \\lim_{n \\to ∞} \\PR(B_n).\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe proof of parts (a) and (b) is elementary and left as an exercise. Part (c) is more technical and is essentially equivalent to countable additivity. See the textbook for a proof.\n\n\n\n\nExample 3 Let \\(Ω = [0,1]\\), \\(\\ALPHABET F = \\mathscr B[0,1]\\), and \\(\\PR\\) be any probability measure on \\((Ω, \\ALPHABET F)\\). Take any \\(a \\in (0,1)\\).\n\nConsider \\(A_n = \\bigl[0, a - \\frac 1n \\bigr)\\). Then \\(A = \\lim_{n \\to ∞} A_n =  [0, a)\\).\nConsider \\(A_n = \\bigl[0, a - \\frac 1n \\bigr]\\). Then \\(A = \\lim_{n \\to ∞} A_n =  [0, a)\\).\nConsider \\(B_n = \\bigl[0, 1 + \\frac 1n \\bigr)\\). Then \\(B = \\lim_{n \\to ∞} B_n = [0,a]\\).\nConsider \\(B_n = \\bigl[0, 1 + \\frac 1n \\bigr]\\). Then \\(B = \\lim_{n \\to ∞} B_n = [0,a]\\).\n\nIn these examples, continuity implies that \\(\\PR(A) = \\lim_{n \\to ∞} \\PR(A_n)\\) and \\(\\PR(B) = \\lim_{n \\to ∞} \\PR(B_n)\\).\n\n\n\n\n\n\n\nSome terminology\n\n\n\n\nAn event \\(A\\) is called null if \\(\\PR(A) = 0\\). Null event should not be confused with impossible event \\(\\emptyset\\).\nWe say that \\(A\\) occurs almost surely (abbreviated to a.s.) if \\(\\PR(A) = 1\\).\n\n\n\n\nExample 4 Consider \\(Ω = [0,1]\\), \\(\\ALPHABET F = \\mathscr B([0,1])\\), and \\(\\PR\\) to be the uniform probability distribution on \\(Ω\\). Consider the event \\(A\\) that the outcome is a rational number. \\(A\\) is a countable set (because the set of rational numbers is countable). For any \\(x \\in A\\), \\(\\{x\\} \\in \\ALPHABET F\\), and \\(\\PR(\\{x\\}) = 0\\) (we can infer this from Example 3 by thinking of \\(\\{x\\}\\) as the limit of intervals \\(\\bigl[x, x+ \\frac 1n\\bigr]\\)). Thus, by countable additivity, \\(\\PR(A) = 0\\). Hence, \\(A\\) is null.\nThe above analysis implies that \\(\\PR(A^c) = 1\\), thus the event that the outcome is irrational occurs almost surely."
  },
  {
    "objectID": "probability-spaces.html#conditional-probability",
    "href": "probability-spaces.html#conditional-probability",
    "title": "Introduction to Probability",
    "section": "4 Conditional Probability",
    "text": "4 Conditional Probability\nConditional probabilities quantify the uncertainty of an event when it is known that another event has occurred\n\nDefinition 2 Let \\((Ω,\\ALPHABET F, \\PR)\\) be a probability space and \\(A, B \\in \\ALPHABET F\\) such that \\(\\PR(B) &gt; 0\\). Then, the conditional probability that \\(A\\) occurs given that \\(B\\) occurs is defined as \\[\n\\PR(A | B) = \\dfrac{ \\PR(A \\cap B) }{ \\PR(B) }.\n\\]\n\nThe notation \\(\\PR(A | B)\\) is read as “probability of \\(A\\) given \\(B\\)” or “probability of \\(A\\) conditioned on \\(B\\)”.\n\nExercise 6 Suppose we roll a fair six-sided dice (a fair dice means that all outcomes are equally likely). Consider the events \\(A\\) that the outcomes is prime and \\(B\\) that the outcome is a multiple of \\(3\\). Compute \\(\\PR(A | B)\\) and \\(\\PR(B | A)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe have \\(Ω = \\{1, 2, 3, 4, 5, 6\\}\\), \\(A = \\{2, 3, 5\\}\\), and \\(B = \\{3, 6\\}\\). Note that \\(\\PR(A) = \\frac 12\\) and \\(\\PR(B) = \\frac 13\\).\nThus, \\[ \\PR(A | B) = \\frac{ \\PR(A \\cap B) }{ \\PR(B) }\n= \\frac{ \\PR(\\{3\\}) }{ \\PR(\\{3,6\\}) }\n= \\frac{ \\ABS{\\{3\\}} }{ \\ABS{\\{3,6\\}} } = \\frac {1}{2}.\n\\] Similarly, \\[ \\PR(B | A) = \\frac{ \\PR(B \\cap A) }{ \\PR(A) }\n= \\frac{ \\PR(\\{3\\}) }{ \\PR(\\{2,3,5\\}) }\n= \\frac{ \\ABS{\\{3\\}} }{ \\ABS{\\{2,3,5\\}} } = \\frac {1}{3}.\n\\]\n\n\n\n\nExercise 7 Suppose we roll two fair six-sided dice. Consider the event \\(A\\) that the minimum of the two rolls is greater than or equal to \\(6\\) and the event \\(B\\) that the maximum of the two rolls is less than or equal to \\(8\\). Compute \\(\\PR(A|B)\\) and \\(\\PR(B|A)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNote that \\(Ω = \\{ 1, 2,3, 4, 5, 6\\}^2\\) and \\(\\PR\\) is uniform probability on all outcomes. The sets \\(A\\), \\(B\\), and \\(A \\cap B\\) are shown in Figure 1. Note that \\(\\PR(A) = \\PR(B) = \\frac{26}{36} = \\frac{13}{18}\\).\n\n\n\n\n\n\nFigure 1: The different events in Exercise 7\n\n\n\nThus, we have \\[\n\\PR(A|B) = \\frac{ \\PR(A \\cap B) } { \\PR(B) }\n= \\frac{ \\ABS{ A \\cap B} }{ \\ABS{B} }\n= \\frac{16}{26} = \\frac{8}{13}\n\\] and \\[\n\\PR(B|A) = \\frac{ \\PR(B \\cap A) } { \\PR(A) }\n= \\frac{ \\ABS{ B \\cap A} }{ \\ABS{A} }\n= \\frac{16}{26} = \\frac{8}{13}\n\\]\n\n\n\n\n\n\n\n\n\nConditional probabilities are legitimate probability measures on \\((Ω, \\ALPHABET F)\\). In particular, if \\(\\PR(B) &gt; 0\\), then\n\n\\(\\PR(A \\mid B) \\ge 0\\).\n\\(\\PR(Ω \\mid B) = \\dfrac{\\PR(Ω \\cap B)}{\\PR(B)} = 1\\).\nFor disjoint events \\(A_1, A_2 \\in \\ALPHABET F\\), \\(\\PR(A_1 \\cup A_2 \\mid B) = \\PR(A_1 \\mid B) + \\PR(A_2 \\mid B)\\).\n\n\n\n\n\nLemma 2 (Law of total probability) Let \\(\\{B_1, B_2, \\dots, B_m\\}\\) be a partition of \\(Ω\\) such that \\(\\PR(B_i) &gt; 0\\) for all \\(i\\). Then, \\[\n\\PR(A) = \\sum_{i=1}^m \\PR(A | B_i) \\PR(B_i).\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider \\(m=2\\), in which case the result can be simplified as \\[\\PR(A) = \\PR(A|B)\\PR(B) + \\PR(A|B^c) \\PR(B^c).\\]\nTo prove this observe that \\[\\begin{equation}\\label{eq:two-step}\nA = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c).\n\\end{equation}\\] The events \\(A \\cap B\\) and \\(A \\cap B^c\\) are disjoint. Therefore, by additivity, we have \\[\n\\PR(A) = \\PR(A \\cap B) + \\PR(A \\cap B^c).\n\\] Then, by the definition of conditional probability, we have \\(\\PR(A \\cap B) = \\PR(A|B) \\PR(B)\\) and \\(\\PR(A \\cap B^c) = \\PR(A|B^c) \\PR(B^c)\\). Substituting in the above, we get \\(\\eqref{eq:two-step}\\).\nThe argument for the general case is similar.\n\n\n\n\nLemma 3 (Bayes rule) For any events \\(A, B \\in \\ALPHABET F\\) such that \\(\\PR(A), \\PR(B) &gt; 0\\), we have \\[\n\\PR(B|A) = \\dfrac{\\PR(A|B)\\PR(B)}{\\PR(A)}.\n\\]\nIn general, if \\(\\{B_1, B_2, \\dots, B_m\\}\\) is a partition of \\(Ω\\) such that \\(\\PR(B_i) &gt; 0\\) for all \\(i\\). Then, \\[\n\\PR(B_i|A) =\n\\dfrac{ \\PR(A|B_i) \\PR(B_i) }\n{\\displaystyle \\sum_{j=1}^m \\PR(A|B_j) \\PR(B_j)}\n\\] where we have used the law of total probability (Lemma 2) in the denominator."
  },
  {
    "objectID": "probability-spaces.html#independence",
    "href": "probability-spaces.html#independence",
    "title": "Introduction to Probability",
    "section": "5 Independence",
    "text": "5 Independence\nIn general, the knowledge that an event \\(B\\) has occurred changes the probability of event \\(A\\), since \\(\\PR(A)\\) is replaced by \\(\\PR(A|B)\\). If the knowledge that \\(B\\) has occurred does not does not change our belief about \\(A\\), i.e., when \\(\\PR(A|B) = \\PR(A)\\), we say “\\(A\\) and \\(B\\) are independent”. This leads to the following definition.\n\nDefinition 3 The events \\(A, B \\in \\ALPHABET F\\) are called independent if \\[\n\\PR(A|B) = \\PR(A)\n\\quad\\text{or}\\quad\n\\PR(B|A) = \\PR(B).\n\\] An alternative but equivalent definition is \\[\n\\PR(A \\cap B) = \\PR(A) \\PR(B).\n\\]\nIn general, a family of events \\(\\{A_1, A_2, \\dots, A_n\\}\\) is called independent if \\[\n\\PR\\biggl( \\bigcap_{i=1}^n A_i \\biggr) =\n\\prod_{i=1}^n \\PR(A_i).\n\\]\n\n\n\n\n\n\n\nIt is common for students to make the mistake and think that independence means \\(A \\cap B = \\emptyset\\). This is not true!\n\n\n\n\nExample 5 The events \\(A\\) and \\(B\\) defined in Exercise 6 are independent.\n\n\nExample 6 The events \\(A\\) and \\(B\\) defined in Exercise 7 are not independent."
  }
]